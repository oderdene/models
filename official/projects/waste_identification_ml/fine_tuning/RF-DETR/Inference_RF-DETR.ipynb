{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGMCRn7pByI2"
      },
      "source": [
        "This notebook demonstrates how to run inference using a model trained with RF-DETR (Region-Focused DEtection TRansformer)â€”a transformer-based object detection framework designed for efficient and accurate detection of objects, particularly in cluttered or regionally focused visual scenes. We will walk through the setup, load the trained weights, and perform predictions on test images or video frames to visualize bounding boxes and class outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgZT49zGYOjH"
      },
      "outputs": [],
      "source": [
        "!pip install -q rfdetr supervision roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YOyKM0PYcV_"
      },
      "outputs": [],
      "source": [
        "# Import libraries.\n",
        "from rfdetr.util.coco_classes import COCO_CLASSES\n",
        "from rfdetr import RFDETRLarge\n",
        "from google.colab import drive\n",
        "import natsort\n",
        "import io\n",
        "import requests\n",
        "import supervision as sv\n",
        "from PIL import Image\n",
        "import warnings\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "import json\n",
        "import glob\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "!export CUDA_LAUNCH_BLOCKING=1\n",
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "\n",
        "# Connect to the google drive.\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "try:\n",
        "  !ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "  print('Successful')\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  print('Not successful')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYmqTYVhCWOv"
      },
      "source": [
        "## Load label and RF-DETR model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljdiw2OtlQ0F"
      },
      "outputs": [],
      "source": [
        "# Define the categories used while training the model.\n",
        "CLASSES = {\n",
        "    0: 'dairy_product_packet'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn3ZezOcYjQM"
      },
      "outputs": [],
      "source": [
        "model = RFDETRLarge(pretrain_weights=\"/mydrive/LLM/rf-detr/data/output/checkpoint_best_total.pth\")\n",
        "model.optimize_for_inference()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTIvD10TEErT"
      },
      "outputs": [],
      "source": [
        "#@title Utils\n",
        "\n",
        "DEFAULT_COLOR_HEX_LIST = [\n",
        "    \"#ffff00\", \"#ff9b00\", \"#ff66ff\", \"#3399ff\", \"#ff66b2\", \"#ff8080\",\n",
        "    \"#b266ff\", \"#9999ff\", \"#66ffff\", \"#33ff99\", \"#66ff66\", \"#99ff00\"\n",
        "]\n",
        "\n",
        "def visualize_detections(\n",
        "    image: Image.Image,\n",
        "    detections: sv.Detections,\n",
        "    class_names: List[str],\n",
        "    threshold: float = 0.5,\n",
        "    color_hex_list: List[str] = DEFAULT_COLOR_HEX_LIST\n",
        ") -\u003e Image.Image:\n",
        "  \"\"\"Visualizes bounding boxes and class labels on an image.\n",
        "\n",
        "  This function uses the Supervision (sv) library to filter detections\n",
        "  by confidence, calculate optimal annotation styles, and draw the\n",
        "  annotations on a copy of the input image.\n",
        "\n",
        "  Args:\n",
        "      image (Image.Image): Input image from PIL.\n",
        "      detections (sv.Detections): Output from the detection model.\n",
        "      class_names (List[str]): List mapping class IDs to class names.\n",
        "      threshold (float, optional): Minimum confidence score to keep\n",
        "          a detection. Defaults to 0.5.\n",
        "      color_hex_list (List[str], optional): A list of hex color strings\n",
        "          for the color palette. Defaults to DEFAULT_COLOR_HEX_LIST.\n",
        "\n",
        "  Returns:\n",
        "      Image.Image: A new annotated image with bounding boxes and\n",
        "          class labels.\n",
        "  \"\"\"\n",
        "  # Filter detections by confidence threshold\n",
        "  detections = detections[detections.confidence \u003e threshold]\n",
        "\n",
        "  # Determine optimal text scale and box thickness based on image resolution\n",
        "  text_scale = sv.calculate_optimal_text_scale(resolution_wh=image.size)\n",
        "  thickness = sv.calculate_optimal_line_thickness(resolution_wh=image.size)\n",
        "\n",
        "  # Define color palette from the provided hex list\n",
        "  color_palette = sv.ColorPalette.from_hex(color_hex_list)\n",
        "\n",
        "  # Set up annotators\n",
        "  box_annotator = sv.BoxAnnotator(\n",
        "      color=color_palette,\n",
        "      thickness=thickness)\n",
        "\n",
        "  label_annotator = sv.LabelAnnotator(\n",
        "      color=color_palette,\n",
        "      text_color=sv.Color.BLACK,\n",
        "      text_scale=text_scale,\n",
        "  )\n",
        "\n",
        "  # Generate label strings\n",
        "  labels = [\n",
        "      f\"{class_names[class_id]} {confidence:.2f}\"\n",
        "      for class_id, confidence in zip(\n",
        "          detections.class_id, detections.confidence)\n",
        "  ]\n",
        "\n",
        "  # Create annotated copy of the image\n",
        "  # We use keyword arguments for clarity on the `annotate` calls\n",
        "  annotated_image = image.copy()\n",
        "  annotated_image = box_annotator.annotate(\n",
        "      scene=annotated_image,\n",
        "      detections=detections\n",
        "  )\n",
        "\n",
        "  annotated_image = label_annotator.annotate(\n",
        "      scene=annotated_image,\n",
        "      detections=detections,\n",
        "      labels=labels\n",
        "  )\n",
        "\n",
        "  return annotated_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U5n-eUoCfb_"
      },
      "source": [
        "## Read images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek2JTOvokZ6B"
      },
      "outputs": [],
      "source": [
        "files = glob.glob('/mydrive/LLM/milk_pouches/data/dairy/images/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3jVfGBCk4r6"
      },
      "outputs": [],
      "source": [
        "image = Image.open(files[25])\n",
        "detections = model.predict(image, threshold=0.50)\n",
        "annotated = visualize_detections(\n",
        "    image=image,\n",
        "    detections=detections,\n",
        "    class_names=CLASSES,\n",
        "    threshold=0.50\n",
        ")\n",
        "\n",
        "sv.plot_image(annotated)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
